# -*- coding: utf-8 -*-
"""B21AI027_lab_assignment_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_ZJtUaFK_zUwPylk-KUZiqJfciM2sa6g

#Question 1

##Part 1
"""

#Setting up dataset
import os
os.system("wget https://www.dropbox.com/s/za7yb0cpfpewz4z/titanic.csv")

#importing dataset
import pandas as pd
df=pd.read_csv("titanic.csv")

df.head()

#preprocessing
df=df.drop(["Name","Ticket","Cabin","PassengerId"],axis=1)

#check not filled rows
df.isnull().sum()

#filling not filled values with mean 
df["Age"]=df["Age"].fillna(df["Age"].mean().round(0))

df.isnull().sum()

#show row with not filled values in embarked
df[df["Embarked"].isnull()]

#removing the above two rows
df=df.drop(829,axis=0)
df=df.drop(61,axis=0)

#one-hot encode the "Sex/gender" column
# 0 for male and 1 for female
df["Sex"] = df["Sex"].map({"male": 0, "female": 1})

#visualizing data for every column
import matplotlib.pyplot as plt
import seaborn as sns
g = sns.FacetGrid(df, col='Survived')
g.map(sns.histplot, 'Pclass',bins=10)

g = sns.FacetGrid(df, col='Survived')
g.map(sns.histplot, 'Age',bins=10)

g = sns.FacetGrid(df, col='Survived')
g.map(sns.histplot, 'Fare',bins=10)

g = sns.FacetGrid(df, col='Survived')
g.map(sns.histplot, 'Embarked',bins=10)

sns.countplot(x='Sex',data=df)
plt.show()

sns.countplot(x='Survived',data=df)
plt.show()

#one-hot encode Embarked column
df= pd.get_dummies(df, columns = ['Embarked'])
df

#Converting to X and y
preservedy=y=df['Survived']
preservedX=X=df.drop(['Survived'],axis=1)

#train test split
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)

X_train

y_train

df

"""##Part 2

features Age and Fare are continuous and feature which are categorical are(Pclass, Sex, Embarked, and Survived).
so best variant is gaussian naive bayes
This classifier looks for continous features which are normally distributed and it fullfills our condition in dataset
this classifier is based on the probabilistic approach and Gaussian distribution

##Part 3
"""

# Normalize all features between 0 and 1
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

# scaling on the training data & test data and transform it
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_score
gnb = GaussianNB()
gnb.fit(X_train, y_train)

gnbcv = GaussianNB()
score = cross_val_score(gnb, X, y, cv=5)
print("Scores is: ",score.mean())
print("Std is: ", score.std())

from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.metrics import roc_curve

y_prob = gnb.predict_proba(X_test)[:,1]
y_pred = gnb.predict(X_test)

#ROC AUC score
roc_auc = roc_auc_score(y_test, y_prob)
print("ROC AUC:", roc_auc)

# false positive rate and true positive rate
fpr, tpr, thresholds = roc_curve(y_test, y_prob)

# Plot the ROC AUC curve
plt.plot(fpr, tpr, label="ROC Curve (AUC = %0.2f)" % roc_auc)
plt.plot([0, 1], [0, 1], "k--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Receiver Operating Characteristic Curve")
plt.legend(loc="lower right")
plt.show()

accuracy_score(y_pred,y_test)

"""##Part 4"""

from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import KFold
from sklearn import metrics
import numpy as np

# Save a copy of the original X and y to use later
X=preservedX
y=preservedy

scaler = MinMaxScaler()

gnb = GaussianNB()
kf = KFold(n_splits=5)
scores = []

for train_index, test_index in kf.split(X):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    
    # Normalise
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    gnb.fit(X_train, y_train)
    y_pred = gnb.predict(X_test)
    score = metrics.accuracy_score(y_test, y_pred)
    scores.append(score)



# Calculate the mean and standard deviation of the accuracy scores
mean_score = np.mean(scores)
std_score = np.std(scores)

print(f"Mean accuracy: {mean_score}")
print(f"Standard deviation: {std_score}")


#For calculating prob of top class
y_prob = gnb.predict_proba(X_test)

#probability of the top class for each row in the testing dataset.
top_class_index = np.argmax(y_prob, axis=1)
top_class_prob = y_prob[np.arange(len(y_prob)), top_class_index]

#plot the top_class_prob
plt.hist(top_class_prob)
plt.xlabel("Probability of Top Class")
plt.ylabel("No of Samples")
plt.show()

"""##Part 5"""

X=preservedX
y=preservedy

X=X[['Age','Fare']]

# Normalise
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

# fitting model
gnb = GaussianNB()
gnb.fit(X, y)

# making contour plot
x = np.linspace(np.min(X[:,0]), np.max(X[:,0]), 889)
y = np.linspace(np.min(X[:,1]), np.max(X[:,1]), 889)
X_axis, Y_axis = np.meshgrid(x, y)
XX = np.array([X_axis.ravel(), Y_axis.ravel()]).T
Z = gnb.predict_proba(XX)[:,1].reshape(X_axis.shape)

plt.contourf(X_axis, Y_axis, Z)
plt.scatter(X[y==0,0], X[y==0,1], c='b')
plt.scatter(X[y==1,0], X[y==1,1], c='g')
plt.xlim(np.min(X[:,0]), np.max(X[:,0]))
plt.ylim(np.min(X[:,1]), np.max(X[:,1]))
plt.show()

"""##Part 6"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

dt=DecisionTreeClassifier(max_depth=8)
X=preservedX
y=preservedy

# Normalise
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

score = cross_val_score(dt, X, y, cv=5)

print("Scores is: ",score.mean())
print("Std is: ", score.std())

"""#Question 2

##Part a
"""

import os
os.system("wget https://www.dropbox.com/s/ubaniiu9xn6of9m/dataset%20%281%29.csv")

import pandas as pd
df=pd.read_csv("dataset (1).csv")

df.columns = ['Area', 'Perimeter', 'Compactness', 'Length of kernel', 'Width of kernel',
                'Asymmetry coefficient', 'Length of kernel groove', 'Class']

df

import matplotlib.pyplot as plt

for i in range(8):
    plt.figure()
    plt.hist(df.iloc[:,i], bins=30)
    plt.xlabel(df.columns[i])
    plt.ylabel("Frequency")

plt.show()

"""##Part b"""

c1pp=class_1_prior_probability = sum(df['Class'] == 1) / len(df['Class'])
c2pp=class_2_prior_probability = sum(df['Class'] == 2) / len(df['Class'])
c3pp=class_3_prior_probability = sum(df['Class'] == 3) / len(df['Class'])

print(c1pp,c2pp,c3pp)

"""##Part c"""

X=df.drop(['Class'],axis=1)
Y=df['Class']

num_bins=10
num_features = X.shape[1]
X_discretized = np.zeros_like(X, dtype=np.int)
for i in range((num_features)):
    feature=df.iloc[:,i]
    bins = np.linspace(feature.min(), feature.max(), num_bins + 1)
    X_discretized[:, i] = np.digitize(feature, bins)

pd.DataFrame(X_discretized,columns=['Area', 'Perimeter', 'Compactness', 'Length of kernel', 'Width of kernel',
                'Asymmetry coefficient', 'Length of kernel groove'])

"""##Part d"""

uni_class = np.unique(Y)

# class conditional probabilities array
class_cond_probs = np.ones((len(uni_class), num_bins, num_features))

for i, class_value in enumerate(uni_class):
    X_forwhich_Y_choosen = X_discretized[Y == class_value]
    number_samples_of_X = X_forwhich_Y_choosen.shape[0]

    for j in range(num_features):
        feature_col = X_forwhich_Y_choosen[:, j]
        histogram, _ = np.histogram(feature_col, bins=np.arange(num_bins + 1))
        
        # class conditional probability
        class_cond_probs[i, :, j] = histogram / number_samples_of_X

# likelihood
likelihood = np.sum(class_cond_probs, axis=0)

# likelihood normalised to get probabilities
likelihood /= len(uni_class)
print("Class conditional probability shape",class_cond_probs.shape)
print("Class conditional probability",class_cond_probs)
print("Likelihood shape",likelihood.shape)
print("Likelihood",likelihood)


# print("Class conditional probability for each class(bins been summedup) shape",np.sum(class_cond_probs,axis=1).shape)
# print("Class conditional probability for each class(bins been summedup)",np.sum(class_cond_probs,axis=1))
# print("Likelihood for each class(bins been summedup) shape",np.sum(likelihood,axis=0).shape)
# print("Likelihood for each class(bins been summedup)",np.sum(likelihood,axis=0))

"""##Part e"""

for i, class_value in enumerate(uni_class):
    X_forwhich_Y_choosen = X_discretized[Y == class_value]
    number_samples_of_X = X_forwhich_Y_choosen.shape[0]
    for j in range(num_features):
        feature_col = X_forwhich_Y_choosen[:, j]
        temp_df = pd.DataFrame(feature_col, columns=["X"+str(j)])
        sns.countplot(x="X"+str(j), data=temp_df)
        plt.title(f'Class: {class_value}, Feature: {j}')
        plt.show()

"""##Part f"""

# class prior probabilities
class_priors = np.array([np.sum(Y == class_value) / Y.shape[0] for class_value in uni_class])

# posterior probabilities array
posterior_probs = np.ones((len(uni_class), num_bins, num_features))

for i in range(len(uni_class)):
    for j in range(num_bins):
        for k in range(num_features):
            posterior_probs[i, j, k] = class_priors[i] * class_cond_probs[i, j, k] / likelihood[j, k]

# Plotting
fig, axs = plt.subplots(num_features, 1, figsize=(10, 10))

for i in range(num_features):
    for j in range(len(uni_class)):
        axs[i].plot(posterior_probs[j, :, i], label=f'Class {uni_class[j]}')
    axs[i].legend()
    axs[i].set_title(f'Feature {i}')

plt.tight_layout()
plt.show()

df