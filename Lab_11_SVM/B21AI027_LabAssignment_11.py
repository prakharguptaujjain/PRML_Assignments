# -*- coding: utf-8 -*-
"""B21AI027_LabAssignment_11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xrzgeeTHTGgfAJeGZmSLVUzqdXi3z9f9

#Question 1

##Initials
"""

import joblib
import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
import itertools

if os.path.exists('data_banknote_authentication.txt'):
    print("Already Present")
else:
    os.system("wget https://www.dropbox.com/s/wswyatu5mjh6hy0/data_banknote_authentication.txt")

columns=['variance','skewness','curtosis','entropy','classes']
df = pd.read_csv('data_banknote_authentication.txt',names=columns)

df

"""#Part 1"""

df.isnull().sum()

df.dtypes

df.describe()

corr_mat = df.corr()

# plotting
sns.heatmap(corr_mat, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix of df')
plt.show()

for i in df.columns:
    print(len(np.unique(df[i])))

#Scalling the dataset
scaler = MinMaxScaler()
for col in df.columns:
    if(col!='classes'):
        df[col] = scaler.fit_transform(np.array(df[col]).reshape(len(df[col]),1))

#df to X,y
X=df.drop('classes',axis=1)
y=df['classes']

#Splitting dataset
X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, random_state=42)
X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)

"""##Part 2"""

c_vals = [0.0001, 0.01, 1, 100, 1000, 10000]
for C in c_vals:
    svm_clf = SVC(C=C, random_state=42)
    svm_clf.fit(X_train, y_train)
    y_pred = svm_clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print("Classification accuracy for C = {:>6}: {:.4f}".format(C, accuracy))

#Features with best corr with y
feature1 = "variance"
feature2 = "skewness"

# Plotting decision boundaries for different values of C
fig, axes = plt.subplots(len(c_vals), 1, figsize=(len(c_vals), 8*4))

for j, C in enumerate(c_vals):
    # Train SVM classifier
    clf = SVC(kernel='linear', C=C)
    clf.fit(X.values[:, [X_train.columns.get_loc(feature1), X_train.columns.get_loc(feature2)]], y.values)

    # Plotting decision boundary
    xx, yy = np.meshgrid(np.arange(X_test[feature1].min()-0.5, X_test[feature1].max()+0.5, 0.02),
                         np.arange(X_test[feature2].min()-0.5, X_test[feature2].max()+0.5, 0.02))
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    axes[j].contourf(xx, yy, Z, cmap=plt.cm.Paired)

    # Plotting data points
    axes[j].scatter(X_test[feature1], X_test[feature2], c=y_test, cmap=plt.cm.Paired, edgecolors='k')
    axes[j].set_xlabel(feature1)
    axes[j].set_ylabel(feature2)
    axes[j].set_title(f"C = {C}")

    # Printing classification accuracy
    accuracy = clf.score(X_test.values[:, [X_test.columns.get_loc(feature1), X_test.columns.get_loc(feature2)]], y_test.values)
    print("Classification accuracy for C = {:>6}: {:.4f}".format(C, accuracy))

plt.show()

"""##Part 3"""

# Features with best corr with y
feature1 = "variance"
feature2 = "skewness"

# Train SVM with different kernels
kernels = ['linear', 'poly', 'rbf']
fig, axes = plt.subplots(1, len(kernels), figsize=(15, 5))

for i, kernel in enumerate(kernels):
    if kernel == 'poly':
        svm_clf = SVC(kernel=kernel, degree=4, random_state=42)  # Quadratic kernel
    else:
        svm_clf = SVC(kernel=kernel, random_state=42)
    svm_clf.fit(X.values[:, [X_train.columns.get_loc(feature1), X_train.columns.get_loc(feature2)]], y.values)

    # Plot decision boundary
    xx, yy = np.meshgrid(np.arange(X_test[feature1].min()-0.5, X_test[feature1].max()+0.5, 0.02),
                         np.arange(X_test[feature2].min()-0.5, X_test[feature2].max()+0.5, 0.02))
    Z = svm_clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    axes[i].contourf(xx, yy, Z, cmap=plt.cm.Paired)

    # Plot data points
    axes[i].scatter(X_test[feature1], X_test[feature2], c=y_test, cmap=plt.cm.Paired, edgecolors='k')
    axes[i].set_xlabel(feature1)
    axes[i].set_ylabel(feature2)
    axes[i].set_title(f"Kernel: {kernel}")

    # Print classification accuracy
    accuracy = svm_clf.score(X_test[[feature1, feature2]], y_test)
    print(f"Classification accuracy for {kernel} kernel: {accuracy:.4f}")

plt.show()